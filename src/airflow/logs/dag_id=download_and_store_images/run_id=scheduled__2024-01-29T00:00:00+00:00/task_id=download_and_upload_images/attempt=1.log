[2025-04-04T10:19:01.046+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: download_and_store_images.download_and_upload_images scheduled__2024-01-29T00:00:00+00:00 [queued]>
[2025-04-04T10:19:01.133+0000] {taskinstance.py:1083} INFO - Dependencies all met for <TaskInstance: download_and_store_images.download_and_upload_images scheduled__2024-01-29T00:00:00+00:00 [queued]>
[2025-04-04T10:19:01.137+0000] {taskinstance.py:1279} INFO - 
--------------------------------------------------------------------------------
[2025-04-04T10:19:01.141+0000] {taskinstance.py:1280} INFO - Starting attempt 1 of 2
[2025-04-04T10:19:01.142+0000] {taskinstance.py:1281} INFO - 
--------------------------------------------------------------------------------
[2025-04-04T10:19:01.229+0000] {taskinstance.py:1300} INFO - Executing <Task(PythonOperator): download_and_upload_images> on 2024-01-29 00:00:00+00:00
[2025-04-04T10:19:01.253+0000] {standard_task_runner.py:55} INFO - Started process 62 to run task
[2025-04-04T10:19:01.307+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'download_and_store_images', 'download_and_upload_images', 'scheduled__2024-01-29T00:00:00+00:00', '--job-id', '779', '--raw', '--subdir', 'DAGS_FOLDER/dag_data_collect.py', '--cfg-path', '/tmp/tmp938nypv_']
[2025-04-04T10:19:01.309+0000] {standard_task_runner.py:83} INFO - Job 779: Subtask download_and_upload_images
[2025-04-04T10:19:01.874+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/settings.py:249: DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
  SQL_ALCHEMY_CONN = conf.get("database", "SQL_ALCHEMY_CONN")

[2025-04-04T10:19:02.375+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/sqlalchemy.py:124: DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
  return not conf.get("database", "sql_alchemy_conn").startswith("mssql")

[2025-04-04T10:19:03.144+0000] {task_command.py:388} INFO - Running <TaskInstance: download_and_store_images.download_and_upload_images scheduled__2024-01-29T00:00:00+00:00 [running]> on host 0df80d73d4ff
[2025-04-04T10:19:05.514+0000] {taskinstance.py:1509} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=download_and_store_images
AIRFLOW_CTX_TASK_ID=download_and_upload_images
AIRFLOW_CTX_EXECUTION_DATE=2024-01-29T00:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2024-01-29T00:00:00+00:00
[2025-04-04T10:19:07.005+0000] {base.py:73} INFO - Using connection ID 'minio_s3' for task execution.
[2025-04-04T10:19:07.096+0000] {connection_wrapper.py:334} INFO - AWS Connection (conn_id='minio_s3', conn_type='aws') credentials retrieved from login and password.
[2025-04-04T10:19:07.101+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/providers/amazon/aws/utils/connection_wrapper.py:8: DeprecationWarning: extra['host'] is deprecated and will be removed in a future release. Please set extra['endpoint_url'] instead
  #

[2025-04-04T10:19:14.873+0000] {base.py:73} INFO - Using connection ID 'minio_s3' for task execution.
[2025-04-04T10:19:14.877+0000] {connection_wrapper.py:334} INFO - AWS Connection (conn_id='minio_s3', conn_type='aws') credentials retrieved from login and password.
[2025-04-04T10:19:22.328+0000] {base.py:73} INFO - Using connection ID 'minio_s3' for task execution.
[2025-04-04T10:19:22.338+0000] {connection_wrapper.py:334} INFO - AWS Connection (conn_id='minio_s3', conn_type='aws') credentials retrieved from login and password.
[2025-04-04T10:19:24.804+0000] {base.py:73} INFO - Using connection ID 'minio_s3' for task execution.
[2025-04-04T10:19:24.807+0000] {connection_wrapper.py:334} INFO - AWS Connection (conn_id='minio_s3', conn_type='aws') credentials retrieved from login and password.
[2025-04-04T10:19:28.023+0000] {base.py:73} INFO - Using connection ID 'minio_s3' for task execution.
[2025-04-04T10:19:28.033+0000] {connection_wrapper.py:334} INFO - AWS Connection (conn_id='minio_s3', conn_type='aws') credentials retrieved from login and password.
[2025-04-04T10:19:33.136+0000] {base.py:73} INFO - Using connection ID 'minio_s3' for task execution.
[2025-04-04T10:19:33.144+0000] {connection_wrapper.py:334} INFO - AWS Connection (conn_id='minio_s3', conn_type='aws') credentials retrieved from login and password.
[2025-04-04T10:19:43.269+0000] {base.py:73} INFO - Using connection ID 'minio_s3' for task execution.
[2025-04-04T10:19:43.286+0000] {connection_wrapper.py:334} INFO - AWS Connection (conn_id='minio_s3', conn_type='aws') credentials retrieved from login and password.
[2025-04-04T10:19:47.249+0000] {local_task_job.py:273} WARNING - State of this instance has been externally set to failed. Terminating instance.
[2025-04-04T10:19:47.345+0000] {process_utils.py:133} INFO - Sending Signals.SIGTERM to group 62. PIDs of all processes in the group: [62]
[2025-04-04T10:19:47.349+0000] {process_utils.py:84} INFO - Sending the signal Signals.SIGTERM to group 62
[2025-04-04T10:19:47.350+0000] {taskinstance.py:1479} ERROR - Received SIGTERM. Terminating subprocesses.
[2025-04-04T10:19:49.577+0000] {base.py:73} INFO - Using connection ID 'minio_s3' for task execution.
[2025-04-04T10:19:49.586+0000] {connection_wrapper.py:334} INFO - AWS Connection (conn_id='minio_s3', conn_type='aws') credentials retrieved from login and password.
[2025-04-04T10:19:56.343+0000] {base.py:73} INFO - Using connection ID 'minio_s3' for task execution.
[2025-04-04T10:19:56.406+0000] {connection_wrapper.py:334} INFO - AWS Connection (conn_id='minio_s3', conn_type='aws') credentials retrieved from login and password.
[2025-04-04T10:20:09.736+0000] {base.py:73} INFO - Using connection ID 'minio_s3' for task execution.
[2025-04-04T10:20:09.743+0000] {connection_wrapper.py:334} INFO - AWS Connection (conn_id='minio_s3', conn_type='aws') credentials retrieved from login and password.
[2025-04-04T10:20:18.453+0000] {base.py:73} INFO - Using connection ID 'minio_s3' for task execution.
[2025-04-04T10:20:18.462+0000] {connection_wrapper.py:334} INFO - AWS Connection (conn_id='minio_s3', conn_type='aws') credentials retrieved from login and password.
[2025-04-04T10:20:39.108+0000] {base.py:73} INFO - Using connection ID 'minio_s3' for task execution.
[2025-04-04T10:20:39.114+0000] {connection_wrapper.py:334} INFO - AWS Connection (conn_id='minio_s3', conn_type='aws') credentials retrieved from login and password.
[2025-04-04T10:20:47.435+0000] {process_utils.py:147} WARNING - process psutil.Process(pid=62, name='airflow task ru', status='running', started='10:19:00') did not respond to SIGTERM. Trying SIGKILL
[2025-04-04T10:20:47.712+0000] {process_utils.py:84} INFO - Sending the signal Signals.SIGKILL to group 62
[2025-04-04T10:20:49.836+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=62, name='airflow task ru', status='terminated', exitcode=<Negsignal.SIGKILL: -9>, started='10:19:00') (62) terminated with exit code Negsignal.SIGKILL
[2025-04-04T10:20:50.072+0000] {standard_task_runner.py:170} ERROR - Job 779 was killed before it finished (likely due to running out of memory)
